"""
Take the mean Halpha line, run a model comparison analysis over gaussian,
lorentzian, voigt, double gaussian, double lorentzian.  Calc red chi2, delta
BIC, and best-fit parameters.

Finally, calculate and report an equivalent width.

(This entire thing was Generated by ChatGPT o3-mini-high on March 20 2025.)
"""
from os.path import join
import os
import pickle
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.optimize import curve_fit
from cdips.utils.lcutils import p2p_rms


def load() -> tuple:
    """Load spectrum data from a pickle file and estimate flux error.

    Args:
        None.

    Returns:
        tuple: Relative velocity array (dv), normalized flux (flx),
            and estimated flux uncertainty (flx_err).

    Generated by ChatGPT o3-mini-high on March 20 2025.
    """
    datadir = (
        '/Users/luke/Dropbox/proj/cpv/results/movie_sixpanel_specriver/'
        'TIC_141146667_science_wob'
    )
    pklpath = join(datadir, '141146667_specriver_cache.pkl')

    with open(pklpath, 'rb') as f:
        d = pickle.load(f)

    dv = d['xvals'][0]
    flx = d['smooth_mean_flux']
    sel = np.abs(dv) > 3
    flx_err = p2p_rms(flx[sel]) * 50
    return dv, flx, flx_err


def gauss_model(x: np.ndarray, amp: float, center: float, sigma: float,
                offset: float) -> np.ndarray:
    """Gaussian model for an emission line.

    Args:
        x (np.ndarray): Array of velocities.
        amp (float): Amplitude of the Gaussian.
        center (float): Center position of the Gaussian.
        sigma (float): Gaussian width (standard deviation).
        offset (float): Baseline offset.

    Returns:
        np.ndarray: Gaussian function evaluated at x.

    Generated by ChatGPT o3-mini-high on March 20 2025.
    """
    return offset + amp * np.exp(-((x - center) ** 2) / (2 * sigma ** 2))


def lorentz_model(x: np.ndarray, amp: float, center: float, gamma: float,
                  offset: float) -> np.ndarray:
    """Lorentzian model for an emission line.

    Args:
        x (np.ndarray): Array of velocities.
        amp (float): Amplitude of the Lorentzian.
        center (float): Center position of the Lorentzian.
        gamma (float): Half-width at half-maximum.
        offset (float): Baseline offset.

    Returns:
        np.ndarray: Lorentzian function evaluated at x.

    Generated by ChatGPT o3-mini-high on March 20 2025.
    """
    return offset + amp * (gamma ** 2 / ((x - center) ** 2 + gamma ** 2))


def pseudo_voigt(x: np.ndarray, amp: float, center: float, sigma: float,
                 eta: float, offset: float) -> np.ndarray:
    """Pseudo-Voigt profile: a linear combination of Gaussian and Lorentzian.

    Args:
        x (np.ndarray): Array of velocities.
        amp (float): Amplitude of the profile.
        center (float): Center position of the profile.
        sigma (float): Width parameter for both Gaussian and Lorentzian.
        eta (float): Mixing parameter (0: pure Gaussian, 1: pure Lorentzian).
        offset (float): Baseline offset.

    Returns:
        np.ndarray: Pseudo-Voigt function evaluated at x.

    Generated by ChatGPT o3-mini-high on March 20 2025.
    """
    gauss = np.exp(-((x - center) ** 2) / (2 * sigma ** 2))
    lorentz = sigma ** 2 / ((x - center) ** 2 + sigma ** 2)
    return offset + amp * (eta * lorentz + (1 - eta) * gauss)


def double_gauss_model(x: np.ndarray, amp1: float, center1: float,
                       sigma1: float, amp2: float, center2: float,
                       sigma2: float, offset: float) -> np.ndarray:
    """Double Gaussian model for an emission line.

    Args:
        x (np.ndarray): Array of velocities.
        amp1 (float): Amplitude of the first Gaussian.
        center1 (float): Center of the first Gaussian.
        sigma1 (float): Width of the first Gaussian.
        amp2 (float): Amplitude of the second Gaussian.
        center2 (float): Center of the second Gaussian.
        sigma2 (float): Width of the second Gaussian.
        offset (float): Baseline offset.

    Returns:
        np.ndarray: Sum of two Gaussian functions with an offset.

    Generated by ChatGPT o3-mini-high on March 20 2025.
    """
    gauss1 = amp1 * np.exp(-((x - center1) ** 2) / (2 * sigma1 ** 2))
    gauss2 = amp2 * np.exp(-((x - center2) ** 2) / (2 * sigma2 ** 2))
    return offset + gauss1 + gauss2


def double_lorentz_model(x: np.ndarray, amp1: float, center1: float,
                         gamma1: float, amp2: float, center2: float,
                         gamma2: float, offset: float) -> np.ndarray:
    """Double Lorentzian model for an emission line.

    Args:
        x (np.ndarray): Array of velocities.
        amp1 (float): Amplitude of the first Lorentzian.
        center1 (float): Center of the first Lorentzian.
        gamma1 (float): Half-width at half-maximum of the first Lorentzian.
        amp2 (float): Amplitude of the second Lorentzian.
        center2 (float): Center of the second Lorentzian.
        gamma2 (float): Half-width at half-maximum of the second Lorentzian.
        offset (float): Baseline offset.

    Returns:
        np.ndarray: Sum of two Lorentzian functions with an offset.

    Generated by ChatGPT o3-mini-high on March 20 2025.
    """
    lorentz1 = amp1 * (gamma1 ** 2 / ((x - center1) ** 2 + gamma1 ** 2))
    lorentz2 = amp2 * (gamma2 ** 2 / ((x - center2) ** 2 + gamma2 ** 2))
    return offset + lorentz1 + lorentz2


def fit_model(model_func, dv: np.ndarray, flx: np.ndarray,
              flx_err: float, p0: list, bounds: tuple) -> tuple:
    """Fit a given model to the spectrum data.

    Args:
        model_func (callable): The model function to fit.
        dv (np.ndarray): Array of relative velocities.
        flx (np.ndarray): Array of normalized flux values.
        flx_err (float): Estimated uncertainty in flux.
        p0 (list): Initial guess for the model parameters.
        bounds (tuple): Lower and upper bounds for the parameters.

    Returns:
        tuple: Optimal parameters, covariance matrix, fitted flux, number
            of free parameters, reduced chi-squared, and BIC. If the fit
            fails, returns None for parameters and covariance, a NaN array
            for fitted flux, and np.nan for statistics.

    Generated by ChatGPT o3-mini-high on March 20 2025.
    """
    sigma_arr = np.full_like(flx, flx_err)
    try:
        popt, pcov = curve_fit(
            model_func, dv, flx, p0=p0, bounds=bounds,
            sigma=sigma_arr, absolute_sigma=True, maxfev=10000)
        fit_flux = model_func(dv, *popt)
        resid = (flx - fit_flux) / sigma_arr
        chi2 = np.sum(resid ** 2)
        dof = len(dv) - len(popt)
        red_chi2 = chi2 / dof
        bic = chi2 + len(popt) * np.log(len(dv))
    except RuntimeError:
        popt, pcov = None, None
        fit_flux = np.full_like(flx, np.nan)
        red_chi2 = np.nan
        bic = np.nan
    n_params = len(popt) if popt is not None else np.nan
    return popt, pcov, fit_flux, n_params, red_chi2, bic


def analyze_mean_halpha():
    """Fit H-alpha emission line with various functional forms.

    This function loads the spectrum data, fits it with Gaussian,
    Lorentzian, Pseudo-Voigt, Double Gaussian, Double Lorentzian
    profiles, creates a two-panel plot with the fits (with errorbars) and
    their residuals, prints two pandas DataFrames: one listing reduced
    chi-squared, number of free parameters, and BIC for each model, and
    another summarizing the best-fit parameters with their uncertainties.
    Finally, it identifies the best model by BIC and calculates the
    equivalent width by integrating the model over two domains.

    Generated by ChatGPT o3-mini-high on March 20 2025.
    """
    dv, flx, flx_err = load()

    amp_guess = np.max(flx) - np.min(flx)
    center_guess = 0
    width_guess = 1  # Appropriate given dv ~ -5 to 5
    offset_guess = np.min(flx)

    bounds_gauss = (
        [0, np.min(dv), 0, -np.inf],
        [np.inf, np.max(dv), np.ptp(dv), np.inf]
    )
    bounds_lorentz = bounds_gauss
    bounds_voigt = (
        [0, np.min(dv), 0, 0, -np.inf],
        [np.inf, np.max(dv), np.ptp(dv), 1, np.inf]
    )
    bounds_dgauss = (
        [0, np.min(dv), 0, 0, np.min(dv), 0, -np.inf],
        [np.inf, np.max(dv), np.ptp(dv), np.inf, np.max(dv),
         np.ptp(dv), np.inf]
    )
    bounds_dlorentz = bounds_dgauss

    models = {
        'Gaussian': {
            'func': gauss_model,
            'p0': [amp_guess, center_guess, width_guess, offset_guess],
            'bounds': bounds_gauss
        },
        'Lorentzian': {
            'func': lorentz_model,
            'p0': [amp_guess, center_guess, width_guess, offset_guess],
            'bounds': bounds_lorentz
        },
        'Pseudo-Voigt': {
            'func': pseudo_voigt,
            'p0': [amp_guess, center_guess, width_guess, 0.5, offset_guess],
            'bounds': bounds_voigt
        },
        'Double Gaussian': {
            'func': double_gauss_model,
            'p0': [amp_guess * 0.6, center_guess, width_guess,
                   amp_guess * 0.4, center_guess, width_guess * 3,
                   offset_guess],
            'bounds': bounds_dgauss
        },
        'Double Lorentzian': {
            'func': double_lorentz_model,
            'p0': [amp_guess * 0.6, center_guess, width_guess,
                   amp_guess * 0.4, center_guess, width_guess * 3,
                   offset_guess],
            'bounds': bounds_dlorentz
        }
    }

    fit_results = {}
    summary_list = []

    for name, info in models.items():
        popt, pcov, fit_flux, n_params, red_chi2, bic = fit_model(
            info['func'], dv, flx, flx_err, info['p0'], info['bounds'])
        fit_results[name] = {
            'popt': popt,
            'pcov': pcov,
            'fit_flux': fit_flux,
            'n_params': n_params,
            'red_chi2': red_chi2,
            'BIC': bic
        }
        summary_list.append({
            'Model': name,
            'n_params': n_params,
            'Reduced Chi2': red_chi2,
            'BIC': bic
        })

    summary_df = pd.DataFrame(summary_list)

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10),
                                    sharex=True)
    ax1.errorbar(dv, flx, yerr=np.full_like(flx, flx_err),
                 fmt='k.', label='Data')
    for name, result in fit_results.items():
        ax1.plot(dv, result['fit_flux'], label=name)
    ax1.set_ylabel('Normalized Flux')
    ax1.legend()
    ax1.set_title('Fits to H-alpha Emission Line')

    for name, result in fit_results.items():
        ax2.plot(dv, flx - result['fit_flux'], label=name)
    ax2.set_xlabel('Velocity (v_eq units)')
    ax2.set_ylabel('Residuals')
    ax2.legend()
    ax2.set_title('Residuals of the Fits')

    plt.tight_layout()
    fig.savefig('results/emission_line_fits/emission_line_fits.png', dpi=300)

    print("Model Fit Statistics:")
    print(summary_df)

    # Build summary table for best-fit parameters and their uncertainties.
    param_names = {
        'Gaussian': ['amp', 'center', 'sigma', 'offset'],
        'Lorentzian': ['amp', 'center', 'gamma', 'offset'],
        'Pseudo-Voigt': ['amp', 'center', 'sigma', 'eta', 'offset'],
        'Double Gaussian': ['amp1', 'center1', 'sigma1',
                            'amp2', 'center2', 'sigma2', 'offset'],
        'Double Lorentzian': ['amp1', 'center1', 'gamma1',
                              'amp2', 'center2', 'gamma2', 'offset']
    }
    params_summary_list = []
    for model_name, result in fit_results.items():
        popt = result['popt']
        pcov = result['pcov']
        if popt is not None and pcov is not None:
            perr = np.sqrt(np.diag(pcov))
            for pname, val, err in zip(param_names[model_name],
                                       popt, perr):
                params_summary_list.append({
                    'Model': model_name,
                    'Parameter': pname,
                    'Value': val,
                    'Uncertainty': err
                })
    params_summary_df = pd.DataFrame(params_summary_list)
    print("\nBest-fit Parameters Summary:")
    print(params_summary_df)

    # Identify the best model by lowest BIC.
    valid_models = {m: info['BIC'] for m, info in fit_results.items()
                    if not np.isnan(info['BIC'])}
    if valid_models:
        best_model_name = min(valid_models, key=valid_models.get)
        best_model_func = models[best_model_name]['func']
        best_params = fit_results[best_model_name]['popt']
        best_fit_flux = best_model_func(dv, *best_params)

        # Conversion factor: dv (in v_eq units) to wavelength.
        # v_eq = 130 km/s, lambda0 for H-alpha = 6562.8 Angstrom,
        # c = 299792.458 km/s.
        conversion_factor = (130 * 6562.8) / 299792.458

        # Calculate equivalent widths.
        sel_domain = np.abs(dv) < 1
        ew_narrow = np.trapz((best_fit_flux[sel_domain] - 1) *
                             conversion_factor, dv[sel_domain])
        ew_total = np.trapz((best_fit_flux - 1) * conversion_factor, dv)

        ew_table = pd.DataFrame({
            'Domain': ['|dv|<1', 'All dv'],
            'Equivalent Width (Angstroms)': [ew_narrow, ew_total]
        })

        print("\nEquivalent Width Calculations:")
        print("Best model (lowest BIC):", best_model_name)
        print(ew_table)
    else:
        print("No valid model fits to compute equivalent widths.")


if __name__ == "__main__":
    analyze_mean_halpha()

