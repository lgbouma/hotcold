import pickle
import os
from os.path import join
from scipy.ndimage import gaussian_filter1d
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
import pandas as pd
from aesthetic.plot import savefig, set_style
from cdips.utils.lcutils import p2p_rms
from scipy.optimize import curve_fit
from typing import List, Optional, Tuple
from matplotlib import rcParams


def double_gauss(x: np.ndarray, a1: float, mu1: float, sigma1: float,
                 a2: float, mu2: float, sigma2: float) -> np.ndarray:
    """Double Gaussian function.

    Computes the sum of two Gaussian functions given the amplitudes,
    means, and standard deviations.

    Parameters:
        x (np.ndarray): Independent variable.
        a1 (float): Amplitude of the first Gaussian.
        mu1 (float): Mean of the first Gaussian.
        sigma1 (float): Standard deviation of the first Gaussian.
        a2 (float): Amplitude of the second Gaussian.
        mu2 (float): Mean of the second Gaussian.
        sigma2 (float): Standard deviation of the second Gaussian.

    Returns:
        np.ndarray: Evaluated double Gaussian function.

    Generated by ChatGPT o3-mini-high on April 1 2025.
    """
    return (a1 * np.exp(-((x - mu1)**2) / (2 * sigma1**2)) +
            a2 * np.exp(-((x - mu2)**2) / (2 * sigma2**2)))


def single_gauss(x: np.ndarray, a: float, mu: float, sigma: float) -> np.ndarray:
    """Single Gaussian function.

    Computes a single Gaussian function given its amplitude, mean, and
    standard deviation.

    Parameters:
        x (np.ndarray): Independent variable.
        a (float): Amplitude of the Gaussian.
        mu (float): Mean of the Gaussian.
        sigma (float): Standard deviation of the Gaussian.

    Returns:
        np.ndarray: Evaluated Gaussian function.

    Generated by ChatGPT o3-mini-high on April 1 2025.
    """
    return a * np.exp(-((x - mu)**2) / (2 * sigma**2))


def fit_double_gaussian(
    x: np.ndarray,
    y: np.ndarray,
    x_fit: np.ndarray,
    p0: List[float],
    lower_bounds: Optional[List[float]] = None,
    upper_bounds: Optional[List[float]] = None,
    y_err: np.ndarray = None
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, pd.DataFrame]:
    """Fit a double Gaussian model to data.

    Fits the data (x, y) with a model consisting of the sum of two Gaussian
    functions, using initial parameter guesses, optional lower and upper bounds,
    and a grid (x_fit) on which the model is evaluated.

    The model is defined as:
        double_gauss(x) = a1 * exp(-((x - mu1)**2) / (2 * sigma1**2)) +
                          a2 * exp(-((x - mu2)**2) / (2 * sigma2**2))

    Parameters:
        x (np.ndarray): Independent variable data.
        y (np.ndarray): Dependent variable data.
        x_fit (np.ndarray): Grid for evaluating the fitted model.
        p0 (List[float]): Initial parameter guesses for
            [a1, mu1, sigma1, a2, mu2, sigma2].
        lower_bounds (Optional[List[float]]): Lower bounds for parameters.
            Defaults to [0, -5, 0.01, 0, -5, 0.01] if not provided.
        upper_bounds (Optional[List[float]]): Upper bounds for parameters.
            Defaults to [1, 5, 0.4, 1, 5, 0.4] if not provided.

    Returns:
        Tuple containing:
            - best fit parameters (np.ndarray)
            - covariance matrix (np.ndarray)
            - y_fit (np.ndarray): Evaluated model at x_fit.
            - y_component1 (np.ndarray): Gaussian component 1 at x_fit.
            - y_component2 (np.ndarray): Gaussian component 2 at x_fit.
            - pd.DataFrame: DataFrame summarizing best fit parameters and
              diagonal covariance uncertainties.

    Generated by ChatGPT o3-mini-high on April 1 2025.
    """
    if lower_bounds is None:
        lower_bounds = [0, -5, 0.01, 0, -5, 0.01]
    if upper_bounds is None:
        upper_bounds = [1, 5, 0.4, 1, 5, 0.4]

    params, cov = curve_fit(double_gauss, x, y, p0=p0,
                            bounds=(lower_bounds, upper_bounds),
                            sigma=y_err, absolute_sigma=False)

    y_fit = double_gauss(x_fit, *params)
    y_component1 = single_gauss(x_fit, params[0], params[1], params[2])
    y_component2 = single_gauss(x_fit, params[3], params[4], params[5])

    param_names = ['Amplitude1', 'Mean1', 'Sigma1',
                   'Amplitude2', 'Mean2', 'Sigma2']
    uncertainties = np.sqrt(np.diag(cov))
    df = pd.DataFrame({
        'Parameter': param_names,
        'Best Fit': params,
        'Uncertainty': uncertainties
    })
    return params, cov, y_fit, y_component1, y_component2, df

def fit_single_gaussian(
    x: np.ndarray,
    y: np.ndarray,
    x_fit: np.ndarray,
    p0: List[float],
    lower_bounds: Optional[List[float]] = None,
    upper_bounds: Optional[List[float]] = None,
    y_err: np.ndarray = None
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, pd.DataFrame]:
    """Fit a single Gaussian model to data.

    Fits the data (x, y) with a single Gaussian function using initial
    parameter guesses, optional lower and upper bounds, and a grid (x_fit)
    on which the fitted model is evaluated.

    The model is defined as:
        single_gauss(x) = a * exp(-((x - mu)**2) / (2 * sigma**2))

    Parameters:
        x (np.ndarray): Independent variable data.
        y (np.ndarray): Dependent variable data.
        x_fit (np.ndarray): Grid for evaluating the fitted model.
        p0 (List[float]): Initial parameter guesses for [a, mu, sigma].
        lower_bounds (Optional[List[float]]): Lower bounds for parameters.
            Defaults to [0, -5, 0.01] if not provided.
        upper_bounds (Optional[List[float]]): Upper bounds for parameters.
            Defaults to [1, 5, 0.4] if not provided.

    Returns:
        Tuple containing:
            - best fit parameters (np.ndarray)
            - covariance matrix (np.ndarray)
            - y_fit (np.ndarray): Evaluated model at x_fit.
            - pd.DataFrame: DataFrame summarizing best fit parameters and
              diagonal covariance uncertainties.

    Generated by ChatGPT o3-mini-high on April 1 2025.
    """
    if lower_bounds is None:
        lower_bounds = [0, -5, 0.01]
    if upper_bounds is None:
        upper_bounds = [1, 5, 0.4]

    params, cov = curve_fit(
        single_gauss, x, y, p0=p0,
        bounds=(lower_bounds, upper_bounds),
        sigma=y_err, absolute_sigma=False
    )
    y_fit = single_gauss(x_fit, *params)
    param_names = ['Amplitude', 'Mean', 'Sigma']
    uncertainties = np.sqrt(np.diag(cov))
    df = pd.DataFrame({
        'Parameter': param_names,
        'Best Fit': params,
        'Uncertainty': uncertainties
    })
    return params, cov, y_fit, df



def halpha_to_rv_timeseries():
    # Fit heuristic models to the time-dynamic HIRES spectra.
    pkldir = '/Users/luke/Dropbox/proj/cpv/results/movie_sixpanel_specriver/TIC_141146667_science_wob'
    pklpath = join(pkldir, '141146667_specriver_cache.pkl')

    ##########################################
    # Load the cached pickle file and retrieve the data
    ##########################################
    if os.path.exists(pklpath):
        with open(pklpath, 'rb') as f:
            d = pickle.load(f)
    else:
        raise FileNotFoundError(f"The file {pklpath} does not exist.")

    xval = d['xvals'] # Δv/v_eq
    yval = d['yvals'] # the flux (median subtracted)
    orig_flux_arr = d['orig_yvals'] # original flux values (not median subtracted)
    spectimes = d['spectimes']

    t0 = d['t0'] # time of transit center
    period = d['period'] # period of the transit

    _xvals = (spectimes-t0)/period
    specphases = (spectimes-t0)/period - np.min(np.ceil(_xvals))
    # NB: specphases as above is defined in the same way as in the cache

    spec_indices = np.arange(0, len(spectimes))
    spec_indices_fine = np.arange(0, spec_indices.max(), 0.1)
    specphases_fine = np.linspace(specphases.min(), specphases.max(), len(spec_indices_fine))

    ##########################################
    # Initial stack plot of Halpha data
    ##########################################
    set_style('clean')
    fig, ax = plt.subplots(figsize=(1.8,12))

    # Normalize the spectimes values for colormap
    norm = plt.Normalize(min(spectimes), max(spectimes))
    cmap = cm.get_cmap('cividis')

    # Iterate over individual spectra
    for ix, x_row, y_row, spec_time in zip(spec_indices, xval, yval, spectimes):

        # Apply 1D Gaussian smoothing with sigma=4 on y_row
        y_row_smoothed = 1.*y_row
        #y_row_smoothed = gaussian_filter1d(y_row, sigma=4)
        ax.plot(x_row, -ix + y_row_smoothed, color=cmap(norm(spec_time)))

    for ampl in [2.5]:
        clump0_rv_guesses = ampl * np.sin(specphases * 2 * np.pi)
        clump0_rv_guesses_fine = ampl * np.sin(specphases_fine * 2 * np.pi)
        ax.plot(clump0_rv_guesses_fine, -spec_indices_fine, c='gray', alpha=0.3)

    phi1 = np.pi
    for ampl in [3.9]:
        clump1_rv_guesses = ampl * np.sin(specphases * 2 * np.pi + phi1)
        clump1_rv_guesses_fine = ampl * np.sin(specphases_fine * 2 * np.pi  + phi1)
        ax.plot(clump1_rv_guesses_fine, -spec_indices_fine, c='gray', alpha=0.3)

    ax.set_xlabel("xval")
    ax.set_ylabel("yval")

    outdir = 'results/halpha_to_rv_timerseries'
    if not os.path.exists(outdir): os.mkdir(outdir)
    outpath = os.path.join(outdir, f'halpha_stack.png')
    savefig(fig, outpath, dpi=400)

    ##########################################
    # Iterate over individual spectra and fit double gaussian to each over local window.
    ##########################################

    #x_fit = np.linspace(-5, 5, 500)  # Define a fine grid for fitting

    cinner_paramslist = []
    cinner_covslist = []
    cinner_yfitslist = []
    cinner_ycomp1list = []
    cinner_ycomp2list = []
    cinner_dflist = []

    couter_paramslist = []
    couter_covslist = []
    couter_yfitslist = []
    couter_ycomp1list = []
    couter_ycomp2list = []
    couter_dflist = []

    # Iterate over individual spectra
    for ix, x_row, y_row, spec_time, specphase, clump0_guess, clump1_guess in zip(
        spec_indices, xval, yval, spectimes, specphases, clump0_rv_guesses, clump1_rv_guesses
    ):

        x_fit = x_row * 1. # grid for fitting; let it be same as data.
        _sel = np.abs(x_row) > 4
        y_err_val = p2p_rms(y_row[_sel])

        #################### 
        # INNER CLUMP FITTING
        #################### 
        # Select subset of data within local window around predicted velocity
        dx = 1 # half-width
        sel = (
            # require within +/-130km/s of predicted velocity
            (x_row < clump0_guess + dx) & (x_row > clump0_guess - dx)
            # require outside line core
            #&
            #~(np.abs(x_row) < 1)
        )

        x = x_row[sel]
        y = y_row[sel]
        y_err = np.ones(len(y)) * y_err_val

        # Initial parameter guesses & bounds: A, mu, sigma
        p0 = [0.4, clump0_guess, 0.2, 0.4, clump0_guess, 0.2]
        lower_bounds = [0, -5, 0.01, 0, -5, 0]
        upper_bounds = [1, 5, 0.4, 1, 5, 0.4]

        _params, _cov, _y_fit, _y_component1, _y_component2, _df = fit_double_gaussian(
            x, y, x_fit, p0, lower_bounds=lower_bounds, upper_bounds=upper_bounds,
            y_err=y_err
        )
        
        cinner_paramslist.append(_params)
        cinner_covslist.append(_cov)
        cinner_yfitslist.append(_y_fit)
        cinner_ycomp1list.append(_y_component1)
        cinner_ycomp2list.append(_y_component2)
        _df['specindex'] = ix
        _df['specphase'] = specphase
        cinner_dflist.append(_df)

        #################### 
        # OUTER CLUMP FITTING
        #################### 
        # Select subset of data within local window around predicted velocity
        dx = 2 # half-width
        sel = (
            # require within +/-130km/s of predicted velocity
            (x_row < clump1_guess + dx) & (x_row > clump1_guess - dx)
            # require outside line core
            #&
            #~(np.abs(x_row) < 1)
        )

        x = x_row[sel]
        y = y_row[sel]
        y_err = np.ones(len(y)) * y_err_val

        # Initial parameter guesses & bounds: A, mu, sigma
        p0 = [0.4, clump1_guess, 0.2]
        lower_bounds = [0, -5, 0.01]
        upper_bounds = [1, 5, 1]

        _params, _cov, _y_fit, _df = fit_single_gaussian(
            x, y, x_fit, p0, lower_bounds=lower_bounds, upper_bounds=upper_bounds, y_err=y_err
        )
        
        couter_paramslist.append(_params)
        couter_covslist.append(_cov)
        couter_yfitslist.append(_y_fit)
        _df['specindex'] = ix
        _df['specphase'] = specphase
        couter_dflist.append(_df)

    mdf_inner = pd.concat(cinner_dflist)
    tdf_inner = mdf_inner.pivot(index='specphase', columns='Parameter', values='Best Fit')
    tdf_inner_unc = mdf_inner.pivot(index='specphase', columns='Parameter', values='Uncertainty')

    mdf_outer = pd.concat(couter_dflist)
    tdf_outer = mdf_outer.pivot(index='specphase', columns='Parameter', values='Best Fit')
    tdf_outer_unc = mdf_outer.pivot(index='specphase', columns='Parameter', values='Uncertainty')

    tdf_outer = tdf_outer.rename(columns={
        "Amplitude": "Amplitude3",
        "Mean": "Mean3",
        "Sigma": "Sigma3"
    })
    tdf_outer_unc = tdf_outer_unc.rename(columns={
        "Amplitude": "Amplitude3",
        "Mean": "Mean3",
        "Sigma": "Sigma3"
    })


    ##########################################
    # Multi-Gaussian clump modeling plot of Halpha data
    ##########################################

    plt.close("all")
    #set_style('clean')
    set_style('clean')
    rcParams['font.family'] = 'Arial'
    #fig, axs = plt.subplots(ncols=4, figsize=(5.6,15), sharey=True)
    fig, axs = plt.subplots(ncols=4, figsize=(2.8, 5.5), sharey=True)

    # Normalize the spectimes values for colormap
    norm = plt.Normalize(min(spectimes), max(spectimes))
    cmap = cm.get_cmap('cividis')

    # Iterate over individual spectra
    for ix, x_row, y_row, spec_time, specphase, _y_fit_inner, _y_fit_outer in zip(
        spec_indices, xval, yval, spectimes, specphases, cinner_yfitslist, couter_yfitslist
    ):

        # Apply 1D Gaussian smoothing with sigma=4 on y_row
        y_row_smoothed = 1.*y_row
        #y_row_smoothed = gaussian_filter1d(y_row, sigma=4)

        ax = axs[0]
        ax.plot(x_row, -ix + y_row_smoothed, color=cmap(norm(spec_time)), alpha=1)

        ax = axs[1]
        ax.plot(x_row, -ix + y_row_smoothed, color=cmap(norm(spec_time)), alpha=0.3)
        ax.plot(x_fit, -ix + _y_fit_inner, color=cmap(norm(spec_time)))

        ax = axs[2]
        ax.plot(x_row, -ix + y_row_smoothed, color=cmap(norm(spec_time)), alpha=0.3)
        ax.plot(x_fit, -ix + _y_fit_outer, color=cmap(norm(spec_time)))

        ax = axs[3]
        y_fit_sum = _y_fit_inner + _y_fit_outer
        ax.plot(x_row, -ix + y_row_smoothed - y_fit_sum, color=cmap(norm(spec_time)))

        if (ix+1) % 2 == 0:
            if ix == 1:
                txt = "$\phi$=0.0"
            else:
                txt = "$\phi$=" + f"{specphase:.2f}"
            ax.text(6.9, -ix+0.3, txt, fontsize='x-small', ha='right', va='center')


    # clump0 gray line
    for ampl in [2.5]:
        clump0_rv_guesses = ampl * np.sin(specphases * 2 * np.pi)
        clump0_rv_guesses_fine = ampl * np.sin(specphases_fine * 2 * np.pi)
        for ax in [axs[0], axs[1]]:
            ax.plot(clump0_rv_guesses_fine, -spec_indices_fine, c='gray',
                    alpha=0.3, ls=':', zorder=-1, lw=0.5)
            
    # clump1 gray line
    phi1 = np.pi
    for ampl in [3.9]:
        clump1_rv_guesses = ampl * np.sin(specphases * 2 * np.pi + phi1)
        clump1_rv_guesses_fine = ampl * np.sin(specphases_fine * 2 * np.pi  + phi1)
        ax = axs[0]
        for ax in [axs[0], axs[2]]:
            ax.plot(clump1_rv_guesses_fine, -spec_indices_fine, c='gray',
                    alpha=0.3, ls='-.', zorder=-1, lw=0.5)
            
        #for ax in [axs[3]]:
        #    ax.axvline(x=1, color='k', linestyle='--', linewidth=0.3, alpha=0.3, zorder=-1)
        #    ax.axvline(x=-1, color='k', linestyle='--', linewidth=0.3, alpha=0.3, zorder=-1)

    dvlabel = r"Δ$v$/$v_\mathrm{eq}$"
    fig.text(0.5, 0.06, dvlabel, va='bottom', ha='center', fontsize='large')

    for ax in axs:
        ax.set_xlim([-5.9, 5.9])

    axs[0].set_ylabel("← Time", fontsize='large')
    axs[0].set_yticklabels([])
    axs[0].set_yticks([])
    axs[0].set_ylim([-20.5, 0.5])

    fluxlabel = r"$f_\lambda$ - $f_{\langle t \rangle}$"
    axs[0].set_title(fluxlabel)
    axs[1].set_title("Inner")
    axs[2].set_title("Outer")
    axs[3].set_title("Resid")

    outdir = 'results/halpha_to_rv_timerseries'
    if not os.path.exists(outdir): os.mkdir(outdir)
    outpath = os.path.join(outdir, f'halpha_stack_3clumps.png')
    savefig(fig, outpath, dpi=400)

    ##########################################
    # Which inner clump is which?  Teasing out the actual resulting RV timeseries
    ##########################################
    plt.close("all")

    plt.errorbar(tdf_inner.index, tdf_inner.Mean1, yerr=tdf_inner_unc['Mean1'], fmt='o')
    plt.errorbar(tdf_inner.index, tdf_inner.Mean2, yerr=tdf_inner_unc['Mean2'], fmt='o')

    for ampl in [2.1, 2.85]:
        clump0_rv_guesses_fine = ampl * np.sin(specphases_fine * 2 * np.pi)
        plt.plot(specphases_fine, clump0_rv_guesses_fine, c='gray', alpha=0.3, ls=':', zorder=-1)

    outpath = os.path.join(outdir, f'2gaussclump0_rv_badlabel.png')
    plt.savefig(outpath, dpi=400)
    plt.close("all")

    ##########################################
    # Relabel such that "2" component is the higher velocity, and "1" is the lower velocity.
    # Create merged dataframe with all components.
    ##########################################

    tdf_inner_new = tdf_inner.copy()
    tdf_inner_unc_new = tdf_inner_unc.copy()
    mask = tdf_inner_new['Mean1'].abs() > tdf_inner_new['Mean2'].abs()
    pairs = [('Mean1', 'Mean2'),
            ('Amplitude1', 'Amplitude2'),
            ('Sigma1', 'Sigma2')]

    for c1, c2 in pairs:
        tdf_inner_new.loc[mask, [c1, c2]] = tdf_inner_new.loc[mask, [c2, c1]].values
        tdf_inner_unc_new.loc[mask, [c1, c2]] = tdf_inner_unc_new.loc[mask, [c2, c1]].values

    tdf = pd.concat([tdf_inner_new, tdf_outer], axis=1)
    tdf_unc = pd.concat([tdf_inner_unc_new, tdf_outer_unc], axis=1)

    ##########################################
    # Which inner clump is which?  Repeat plot to confirm relabeling.
    ##########################################

    plt.close("all")
    plt.errorbar(tdf.index, tdf.Mean1, yerr=tdf_unc['Mean1'], fmt='o')
    plt.errorbar(tdf.index, tdf.Mean2, yerr=tdf_unc['Mean2'], fmt='o')

    for ampl in [2.1, 2.85]:
        clump0_rv_guesses_fine = ampl * np.sin(specphases_fine * 2 * np.pi)
        plt.plot(specphases_fine, clump0_rv_guesses_fine, c='gray', alpha=0.3, ls=':', zorder=-1)

    outpath = os.path.join(outdir, f'2gaussclump0_rv_corrlabel.png')
    plt.savefig(outpath, dpi=400)
    plt.close("all")

    ##########################################
    # Three-panel plot for RV, amplitude, and sigma correlations
    ##########################################
    fig, axs = plt.subplots(nrows=3, figsize=(3,7), sharex=True)

    # Panel 1: RV timeseries with errorbars similar to 2gaussclump0_rv_corrlabel
    #axs[0].errorbar(tdf.index, tdf.Mean1, yerr=tdf_unc['Mean1'], fmt='o', label='Mean1', ms=1)
    #axs[0].errorbar(tdf.index, tdf.Mean2, yerr=tdf_unc['Mean2'], fmt='o', label='Mean2', ms=1)
    #axs[0].errorbar(tdf.index, tdf.Mean3, yerr=tdf_unc['Mean3'], fmt='o', label='Mean3', ms=1)
    axs[0].errorbar(tdf.index, tdf.Mean1, yerr=tdf['Sigma1'], fmt='o', label='Mean1', ms=1)
    axs[0].errorbar(tdf.index, tdf.Mean2, yerr=tdf['Sigma2'], fmt='o', label='Mean2', ms=1)
    axs[0].errorbar(tdf.index, tdf.Mean3, yerr=tdf['Sigma3'], fmt='o', label='Mean3', ms=1)

    for ampl in [2.1, 2.85]:
        clump0_rv_guesses_fine = ampl * np.sin(specphases_fine * 2 * np.pi)
        axs[0].plot(specphases_fine, clump0_rv_guesses_fine, c='gray', alpha=0.3, ls=':', zorder=-1)
    for ampl in [3.9]:
        clump1_rv_guesses_fine = ampl * np.sin(specphases_fine * 2 * np.pi + phi1)
        axs[0].plot(specphases_fine, clump1_rv_guesses_fine, c='gray', alpha=0.3, ls='-.', zorder=-1)

    axs[0].set_ylabel("RV")
    axs[0].legend(fontsize='x-small')

    # Panel 2: Scatterplot of Amplitude1 and Amplitude2 vs. specphase index
    axs[1].errorbar(tdf.index, tdf.Amplitude1, yerr=tdf_unc['Amplitude1'], fmt='o', ms=1)
    axs[1].errorbar(tdf.index, tdf.Amplitude2, yerr=tdf_unc['Amplitude2'], fmt='o', ms=1)
    axs[1].errorbar(tdf.index, tdf.Amplitude3, yerr=tdf_unc['Amplitude3'], fmt='o', ms=1)
    axs[1].set_ylabel("Amplitude")

    # Panel 3: Scatterplot of Sigma1 and Sigma2 vs. specphase index
    axs[2].errorbar(tdf.index, tdf.Sigma1, yerr=tdf_unc['Sigma1'], fmt='o', ms=1)
    axs[2].errorbar(tdf.index, tdf.Sigma2, yerr=tdf_unc['Sigma2'], fmt='o', ms=1)
    axs[2].errorbar(tdf.index, tdf.Sigma3, yerr=tdf_unc['Sigma3'], fmt='o', ms=1)
    axs[2].set_xlabel("specphase")
    axs[2].set_ylabel("stdev [*130km/s]")

    # Save the figure to the same directory as before
    outpath = os.path.join(outdir, 'multigaussclump_rv_ampl_sigma_corrlabel.png')
    fig.tight_layout()
    savefig(fig, outpath, dpi=400)
    plt.close("all")

    ##########################################
    # Write summary parameter latex table
    tdf.index = spectimes
    tdf.index.name = 'BTJD'
    tdf_unc.index = spectimes
    tdf_unc.index.name = 'BTJD'

    # Define columns order and formatting specifications.
    cols_means = ['Mean1', 'Mean2', 'Mean3']
    cols_sigma = ['Sigma1', 'Sigma2', 'Sigma3']
    cols_amp = ['Amplitude1', 'Amplitude2', 'Amplitude3']

    # Build a formatted dataframe.
    formatted_rows = []
    for idx in tdf.index:
        row = []
        for col in cols_means:
            row.append(f"{tdf.loc[idx, col]:.3f} "
                    f"$\\pm$ {tdf_unc.loc[idx, col]:.3f}")
        for col in cols_sigma:
            row.append(f"{tdf.loc[idx, col]:.2f} "
                    f"$\\pm$ {tdf_unc.loc[idx, col]:.2f}")
        for col in cols_amp:
            row.append(f"{tdf.loc[idx, col]:.2f} "
                    f"$\\pm$ {tdf_unc.loc[idx, col]:.2f}")
        formatted_rows.append(row)
    formatted_df = pd.DataFrame(
        formatted_rows,
        index=tdf.index,
        columns=cols_means + cols_sigma + cols_amp
    )

    # Convert the dataframe to a LaTeX table.
    latex_str = formatted_df.to_latex(escape=False)

    # Write the LaTeX table to the specified file.
    latexpath = os.path.join(outdir, 'multigauss_parametertable.tex')
    with open(latexpath, 'w') as f:
        f.write(latex_str)
    print(f"Wrote LaTeX table to {latexpath}")

    csvpath = os.path.join(outdir, 'multigauss_parametervaltable.csv')
    tdf.to_csv(csvpath)
    print(f"Wrote CSV table to {csvpath}")
    csvpath = os.path.join(outdir, 'multigauss_parameterunctable.csv')
    tdf_unc.to_csv(csvpath)
    print(f"Wrote CSV table to {csvpath}")

    ##########################################
    # Define manual masks.  Zero-based count.
    # innermost (~2veq) clump 
    mask0 = [1,1,1,1,1,
             1,1,1,0,0, #9 = phi 0.54
             0,1,1,1,1,
             0,0,1,1,1,   #16(start) = phi 0.93       
             0]
    # middle (~2.8veq) clump 
    mask1 = [1,1,1,1,1,
             1,1,1,1,0,
             1,1,1,1,1,
             0,0,1,1,1,
             0]
    # outer clump
    # 8&9 : absorption cancelled out the emission??
    mask2 = [0,0,0,0,1,
             1,1,1,0,0, #10 = phi 0.54.  
             1,1,1,1,1,
             0,0,0,0,0, #16(start) = phi 0.93
             0]


if __name__ == "__main__":
    halpha_to_rv_timeseries()
